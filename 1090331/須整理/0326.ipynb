{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "均價:  1823.3333333333333\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "resp = requests.get('http://blog.castman.net/web-crawler-tutorial/ch2/table/table.html')\n",
    "soup = BeautifulSoup(resp.text,'html.parser')\n",
    "\n",
    "#計算課程平均價格\n",
    "#取得課程所有價格,使用index\n",
    "#方法一\n",
    "\n",
    "prices=[]\n",
    "rows = soup.find('table','table').tbody.find_all('tr')\n",
    "for row in rows:\n",
    "    price = row.find_all('td')[2].text\n",
    "    prices.append(int(price))\n",
    "\n",
    "print('均價: ',sum(prices)/len(prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "均價:  1823.3333333333333\n"
     ]
    }
   ],
   "source": [
    "#方法二\n",
    "\n",
    "prices=[]\n",
    "links=soup.find_all('a')\n",
    "for link in links:\n",
    "    price = link.parent.previous_sibling.text\n",
    "    prices.append(int(price))\n",
    "    \n",
    "print('均價: ',sum(prices)/len(prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['初心者 - Python入門', '初學者', '1490']\n",
      "['Python 網頁爬蟲入門實戰', '有程式基礎的初學者', '1890']\n",
      "['Python 機器學習入門實戰 (預計)', '有程式基礎的初學者', '1890']\n",
      "['Python 資料科學入門實戰 (預計)', '有程式基礎的初學者', '1890']\n",
      "['Python 資料視覺化入門實戰 (預計)', '有程式基礎的初學者', '1890']\n",
      "['Python 網站架設入門實戰 (預計)', '有程式基礎的初學者', '1890']\n"
     ]
    }
   ],
   "source": [
    "#取得每一列所有欄位資訊\n",
    "\n",
    "rows = soup.find('table','table').tbody.find_all('tr')\n",
    "for row in rows:\n",
    "    print([s for s in row.stripped_strings])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初心者 - Python入門 初學者 1490 http://www.pycone.com img/python-logo.png\n",
      "Python 網頁爬蟲入門實戰 有程式基礎的初學者 1890 http://www.pycone.com img/python-logo.png\n",
      "Python 機器學習入門實戰 (預計) 有程式基礎的初學者 1890 http://www.pycone.com img/python-logo.png\n",
      "Python 資料科學入門實戰 (預計) 有程式基礎的初學者 1890 http://www.pycone.com img/python-logo.png\n",
      "Python 資料視覺化入門實戰 (預計) 有程式基礎的初學者 1890 http://www.pycone.com img/python-logo.png\n",
      "Python 網站架設入門實戰 (預計) 有程式基礎的初學者 1890 http://www.pycone.com img/python-logo.png\n"
     ]
    }
   ],
   "source": [
    "rows = soup.find('table','table').tbody.find_all('tr')\n",
    "for row in rows:\n",
    "    all_tds = row.find_all('td')\n",
    "    if 'href' in all_tds[3].a.attrs:\n",
    "        href = all_tds[3].a['href']\n",
    "    else:\n",
    "        herf = None\n",
    "    print(all_tds[0].text,all_tds[1].text,all_tds[2].text,href,all_tds[3].a.img['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "html='<div data-name=\"123\">foo<div>'\n",
    "soup=BeautifulSoup(html,'html.parser')\n",
    "data_tag = soup.find(attrs={'data-name','123'})\n",
    "print(data_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "Y_MOVIE_URL = 'https://movies.yahoo.com.tw/movie_thisweek.html'\n",
    "def get_web_page(url):\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code != 200:\n",
    "        print('Invaid url',resp.url)\n",
    "        return None\n",
    "    else:\n",
    "        return resp.text\n",
    "\n",
    "\n",
    "def get_data(data_str):\n",
    "    pattern = '\\d+-\\d+-\\d+'\n",
    "    match = re.search(pattern,data_str)\n",
    "    if match != None:\n",
    "        return data_str\n",
    "    else:\n",
    "        return match.group(0)\n",
    "    \n",
    "def get_movie_id(url):\n",
    "    try:\n",
    "        movie_id = url.split('.html')[0].split('-')[-1]\n",
    "    except:\n",
    "        movie_id = url\n",
    "    return movie_id\n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "#     page = get_web_page(Y_MOVIE_URL)\n",
    "#     print(get_movie_id('https://movies.yahoo.com.tw/movieinfo_main/%E8%A8%98%E6%86%B6%E5%B1%8B-kiokuya-10470'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'expection': '87%', 'ch_name': '記憶屋', 'eng_name': 'kiokuya', 'movie_id': '10470', 'poster_url': 'https://movies.yahoo.com.tw/x/r/w420/i/o/production/movies/January2020/V6MY1SapAqTFmjnS4ChM-800x1138.jpg', 'release_data': '上映日期 ： 2020-03-27'}\n",
      "{'expection': '89%', 'ch_name': 'Re從零開始的異世界生活 外傳集', 'eng_name': '', 'movie_id': '10480', 'poster_url': 'https://movies.yahoo.com.tw/x/r/w420/i/o/production/movies/January2020/TDRN5rFEzoyTnUEnQ6EN-500x720.jpg', 'release_data': '上映日期 ： 2020-03-27'}\n",
      "{'expection': '88%', 'ch_name': '第六感生死戀', 'eng_name': 'Ghost', 'movie_id': '10504', 'poster_url': 'https://movies.yahoo.com.tw/x/r/w420/i/o/production/movies/March2020/ygqvTlkSMVgefHs3LplV-1000x1424.jpg', 'release_data': '上映日期 ： 2020-03-27'}\n",
      "{'expection': '82%', 'ch_name': '抓住救命稻草的野獸們', 'eng_name': 'Beasts Clawing at Straws', 'movie_id': '10507', 'poster_url': 'https://movies.yahoo.com.tw/x/r/w420/i/o/production/movies/February2020/uxiNS7oVZZ92gPsGXJl5-1280x1834.jpg', 'release_data': '上映日期 ： 2020-03-27'}\n",
      "{'expection': '85%', 'ch_name': '最初的晚餐', 'eng_name': 'The First Supper', 'movie_id': '10510', 'poster_url': 'https://movies.yahoo.com.tw/x/r/w420/i/o/production/movies/March2020/fepasHu2m4U1yL2Vt0d5-1920x2743.jpg', 'release_data': '上映日期 ： 2020-03-27'}\n",
      "{'expection': '96%', 'ch_name': '鏡中驚魂', 'eng_name': 'Look Away', 'movie_id': '10514', 'poster_url': 'https://movies.yahoo.com.tw/x/r/w420/i/o/production/movies/February2020/bu1HJ1AY8lgGskKvRNjo-760x1280.jpg', 'release_data': '上映日期 ： 2020-03-27'}\n",
      "{'expection': '94%', 'ch_name': '無聲救援', 'eng_name': 'Resistance', 'movie_id': '10521', 'poster_url': 'https://movies.yahoo.com.tw/x/r/w420/i/o/production/movies/February2020/j5oB00zSjiNcyTWR1xa0-504x720.jpg', 'release_data': '上映日期 ： 2020-03-27'}\n",
      "{'expection': '82%', 'ch_name': '迷雁返家路', 'eng_name': 'Spread Your Wings', 'movie_id': '10533', 'poster_url': 'https://movies.yahoo.com.tw/x/r/w420/i/o/production/movies/February2020/vEPtfrJ0MXMA8K7Ux67H-504x720.jpg', 'release_data': '上映日期 ： 2020-03-27'}\n",
      "{'expection': '84%', 'ch_name': '託陰2：布拉姆回來了', 'eng_name': 'Brahms: The Boy II', 'movie_id': '10540', 'poster_url': 'https://movies.yahoo.com.tw/x/r/w420/i/o/production/movies/March2020/UwajHV3G3AnIMOUNAoCv-504x720.jpg', 'release_data': '上映日期 ： 2020-03-27'}\n",
      "{'expection': '97%', 'ch_name': '絕命直播', 'eng_name': 'Line of Duty', 'movie_id': '10548', 'poster_url': 'https://movies.yahoo.com.tw/x/r/w420/i/o/production/movies/March2020/ZfXP83HaFCyxjVnKu1HI-2756x3935.jpg', 'release_data': '上映日期 ： 2020-03-27'}\n"
     ]
    }
   ],
   "source": [
    "def get_movies(dom):\n",
    "    soup = BeautifulSoup(dom,'html.parser')\n",
    "    movies=[]\n",
    "    rows = soup.find_all('div','release_info_text')\n",
    "    for row in rows:\n",
    "        movie = dict()\n",
    "        movie['expection']=row.find('div','leveltext').span.text.strip()\n",
    "        movie['ch_name']=row.find('div','release_movie_name').a.text.strip()\n",
    "        movie['eng_name']=row.find('div','release_movie_name').find('div','en').a.text.strip()\n",
    "        movie['movie_id']=get_movie_id(row.find('div','release_movie_name').a['href'])\n",
    "        movie['poster_url']=row.parent.find_previous_sibling('div','release_foto').a.img['src']\n",
    "        movie['release_data'] = get_data(row.find('div','release_movie_time').text)\n",
    "        movies.append(movie)\n",
    "    return movies\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    page = get_web_page(Y_MOVIE_URL)\n",
    "    movies = get_movies(page)\n",
    "    for movie in movies:\n",
    "        print(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expection\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "請輸入地區 : 桃園\n",
      "{'name': '桃園', 'pm25': '37', 'pm25_1': '33'}\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def append_list_pm25():\n",
    "    url = 'https://taqm.epa.gov.tw/pm25/tw/PM25A.aspx?area=1'\n",
    "    html = requests.get(url)\n",
    "    sp = BeautifulSoup(html.text, 'html.parser')\n",
    "    rs = sp.find_all(\"tr\", {\"align\": \"center\", \"style\": \"border-width:1px;border-style:Solid;\"})\n",
    "    for r in rs:\n",
    "        name = r.find('a')\n",
    "        pm25 = r.find_all('span')\n",
    "        dic = {}\n",
    "        dic.setdefault('name',   name.text.strip())\n",
    "        dic.setdefault('pm25',   pm25[0].text.strip())\n",
    "        dic.setdefault('pm25_1', pm25[1].text.strip())\n",
    "        list.append(dic)\n",
    "\n",
    "def get_pm25(name):\n",
    "    for d in list:\n",
    "        if d.get('name') == name:\n",
    "            return d\n",
    "list = []\n",
    "append_list_pm25()\n",
    "\n",
    "name = input(\"請輸入地區 : \")\n",
    "d = get_pm25(name)\n",
    "print(d)\n",
    "print(d.get(\"pm25\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "G_FINANCE_URL = 'https://www.google.com/search?q=2330'\n",
    "def get_web_page(url,stock_id):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
    "                             'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                             'Chrome/66.0.3359.181 Safari/537.36'}  #請求頭 包含大多數的網頁瀏覽器\n",
    "    resp = requests.get(url + stock_id,headers=headers)\n",
    "    if resp.status_code != 200:\n",
    "        print(\"找不到網頁:\",resp.url)\n",
    "        return None\n",
    "    else:\n",
    "        return resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
